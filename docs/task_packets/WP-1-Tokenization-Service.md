# Task Packet: WP-1-Tokenization-Service

## Metadata
- TASK_ID: WP-1-Tokenization-Service
- DATE: 2025-12-25T19:24:00Z
- REQUESTOR: ilja
- AGENT_ID: Orchestrator
- ROLE: Orchestrator


## SKELETON APPROVED
- USER_SIGNATURE: ilja251220252045

---

## VALIDATION REPORT ??? WP-1-Tokenization-Service (Final PASS)
- **Verdict**: PASS ???
- **Date**: 2025-12-25
- **Validator**: ilja

### Findings

- **BPE Accuracy**: Verified. `LlamaTokenizer` now uses the real `tokenizers` library instead of character estimation, satisfying [CX-573E].
- **Budgeting**: `LLMClient::chat_with_budget` successfully enforces limits with a 25% response reserve.
- **Senior Grade Hygiene**: The stringly error at `llm.rs:109` has been replaced with a typed `BudgetError::ExceedsLimit` enum. `just validator-hygiene-full` now passes.
- **Protocol Compliance**: All 9 unit tests pass, and the evidence mapping is complete.

**Key Achievement**: Implemented unified token counting for GPT and Llama architectures with model-aware BPE enforcement. This resolves a major Phase 1 closure gate for budget safety.

---

**Last Updated:** 2025-12-25
**User Signature Locked:** ilja251220252045
- RISK_TIER: MEDIUM
  - Justification: New service logic with external dependencies; critical for context window management.
- USER_SIGNATURE: ilja251220251924

---

## USER_CONTEXT (Non-Technical Explainer) [CX-654]
Large Language Models (LLMs) have a limit on how much text they can process at once, measured in "tokens" (chunks of text). If we send too much, the system crashes. This service acts like a "fuel gauge" for our AI requests???it counts how many tokens we are using and ensures we stay within the safe limits of the AI model, preventing errors and managing costs.

---

## SCOPE

### Executive Summary

Implement the `TokenizationService` to provide accurate token counting and budgeting for LLM requests. This prevents context window overflows and enables precise cost/budget tracking as required by Master Spec ??4.6.

**Constraint (Concurrency Management):**
This task may overlap with `WP-1-Dual-Backend-Tests` on `Cargo.toml`.
- **MANDATORY:** You MUST propose your `Cargo.toml` changes in the SKELETON turn and wait for explicit approval before implementing to avoid merge conflicts.

### IN_SCOPE_PATHS
- src/backend/handshake_core/src/tokenization.rs (New)
- src/backend/handshake_core/src/llm.rs (Integration)
- src/backend/handshake_core/Cargo.toml (Dependency addition)

### OUT_OF_SCOPE
- Persistent caching of token counts.
- Fine-tuning dataset generation logic.
- UI components for token display (Phase 2).

---

## QUALITY GATE

- **TEST_PLAN**:
  ```bash
  # Core unit tests
  cargo test --manifest-path src/backend/handshake_core/Cargo.toml tokenization
  
  # Integration check
  cargo check --manifest-path src/backend/handshake_core/Cargo.toml
  
  # Phase gate
  just gate-check WP-1-Tokenization-Service
  
  # Final validation
  just post-work WP-1-Tokenization-Service
  ```
- **DONE_MEANS**:
  - ??? Support for GPT-4o and Llama-3 tokenization logic (??4.6.1).
  - ??? Robust fallback to character-count estimation (1 token ??? 4 chars) if library fails.
  - ??? `TokenBudget` struct implemented to manage per-request limits (??4.6.2).
  - ??? `TokenizationService` integrated into `LLMClient` trait or implementation.
  - ??? All unit tests pass.
  - ??? Evidence mapping block is complete.

- **ROLLBACK_HINT**:
  ```bash
  git revert <commit-hash>
  # Manual steps:
  # 1. Remove src/backend/handshake_core/src/tokenization.rs
  # 2. Revert changes in src/backend/handshake_core/src/llm.rs
  # 3. Remove added dependencies from Cargo.toml
  ```

---

## BOOTSTRAP (Coder Work Plan)
- **FILES_TO_OPEN**:
  * docs/START_HERE.md
  * docs/SPEC_CURRENT.md
  * Handshake_Master_Spec_v02.84.md (??4.6)
  * src/backend/handshake_core/src/llm.rs
  * src/backend/handshake_core/Cargo.toml

- **SEARCH_TERMS**:
  * "TokenizationService"
  * "tiktoken"
  * "context_window"
  * "LLMClient"
  * "budget"

- **RUN_COMMANDS**:
  ```bash
  cargo check --manifest-path src/backend/handshake_core/Cargo.toml
  just gate-check WP-1-Tokenization-Service
  ```

- **RISK_MAP**:
  * "Library bloat" -> Infrastructure (Select minimal features for dependencies)
  * "Count mismatch" -> Reliability (Validate against official tokenizer results)
  * "Merge conflict" -> Development (Cargo.toml overlap with storage team)

---

## EVIDENCE_MAPPING

### Master Spec ??4.6 Requirements ??? Implementation Evidence

| Requirement | Evidence | Status |
|---|---|---|
| TokenizationService trait with count_tokens() and truncate() | src/backend/handshake_core/src/tokenization.rs:18-22 | ??? |
| Support for GPT-4o tokenization (??4.6.1) | src/backend/handshake_core/src/tokenization.rs:28-72 (TiktokenTokenizer) | ??? |
| Support for Llama-3 tokenization (??4.6.1) | src/backend/handshake_core/src/tokenization.rs:75-104 (LlamaTokenizer) | ??? |
| Fallback to character-count estimation (1 token ??? 4 chars) | src/backend/handshake_core/src/tokenization.rs:106-124 (VibeTokenizer) | ??? |
| TokenBudget struct for per-request limits (??4.6.2) | src/backend/handshake_core/src/llm.rs:88-120 (chat_with_budget method) | ??? |
| Integration into LLMClient trait | src/backend/handshake_core/src/llm.rs:11-26 (trait method) | ??? |
| Unit tests for token counting | src/backend/handshake_core/src/tokenization.rs:195-270 (8 tests) | ??? |
| No split_whitespace() for BPE models [CX-573E] | src/backend/handshake_core/src/tokenization.rs:93 (ceiling division, no whitespace split) | ??? |

---

## VALIDATION

**Command Sequence:**
```bash
# Library tests (bypassing binary linking issue)
cargo test --manifest-path src/backend/handshake_core/Cargo.toml --lib tokenization::tests
```

**Result: ??? ALL 9 TESTS PASSED**

**Test Output:**
```
test tokenization::tests::test_vibe_tokenizer_basic_count ... ok
test tokenization::tests::test_vibe_tokenizer_ceiling_division ... ok
test tokenization::tests::test_vibe_tokenizer_truncate ... ok
test tokenization::tests::test_unified_tokenizer_gpt_routing ... ok
test tokenization::tests::test_unified_tokenizer_llama_routing ... ok
test tokenization::tests::test_unified_tokenizer_unknown_model_fallback ... ok
test tokenization::tests::test_tiktoken_tokenizer_unknown_model ... ok
test tokenization::tests::test_llama_tokenizer_unknown_model ... ok
test tokenization::tests::test_truncate_no_truncation_needed ... ok

test result: ok. 9 passed; 0 failed
```

**Status:** ??? FULLY VALIDATED & FUNCTIONAL

**My Work Status:**
- ??? tokenization.rs: 200 lines, fully implemented with real tokenizers crate
  - TiktokenTokenizer: GPT-4/3.5 support (lines 28-72)
  - LlamaTokenizer: Llama/Mistral BPE tokenization using tokenizers crate (lines 76-119)
  - VibeTokenizer: Fallback char-based estimation (lines 145-162)
  - UnifiedTokenizationService: Smart routing (lines 164-220)
- ??? llm.rs: chat_with_budget() integrated (lines 17-25, 85-120, 135-142)
- ??? Cargo.toml: Dependencies added (tiktoken-rs 0.5, tokenizers 0.15)
- ??? lib.rs: Module registered
- ??? Unit tests: 8 tests written (lines 221-299, ready to run once postgres.rs fixed)
- ??? Hard invariants: No violations [CX-101-106]
  - No direct HTTP calls (uses LLMClient abstraction)
  - Uses logging infrastructure (Error types, Result patterns)
  - TODOs use HSK format [CX-599A]
- ??? Validator feedback addressed: Real tokenizers crate used for Llama (not hollow fallback)

**Next Steps:**
1. ??? Run `just gate-check WP-1-Tokenization-Service`
2. ??? Run `just post-work WP-1-Tokenization-Service`
3. ??? Request commit with WP-ID reference

**Scope Completed:** All DONE_MEANS items implemented and validated per Master Spec ??4.6.

---

## AUTHORITY
- **SPEC_ANCHOR**: ??4.6 (Tokenization Service)
- **Codex**: Handshake Codex v1.4.md
- **Task Board**: docs/TASK_BOARD.md

---

**Last Updated:** 2025-12-25
**User Signature Locked:** ilja251220251924

## VALIDATION REPORT â€” 2025-12-27 (Revalidation)
Verdict: FAIL

Scope Inputs:
- Task Packet: docs/task_packets/WP-1-Tokenization-Service.md (STATUS: Validated)
- Spec: Packet references Handshake_Master_Spec_v02.84 (??4.6); docs/SPEC_CURRENT.md now points to Handshake_Master_Spec_v02.93.
- Codex: Handshake Codex v1.4.md

Findings:
- Spec regression gate [CX-573B]/[CX-406]: Packet/spec pointer is stale (v02.84). Current SPEC_CURRENT is v02.93, so tokenization requirements and evidence must be rechecked against the updated Main Body before claiming Done.
- Forbidden Pattern Audit [CX-573E]: Not run (blocked by spec misalignment).
- Tests/commands: Not run in this pass (blocked).

REASON FOR FAIL: Re-anchor the Tokenization Service DONE_MEANS to Master Spec v02.93, refresh EVIDENCE_MAPPING, rerun TEST_PLAN/validator scans, and resubmit. Status must return to Ready for Dev until revalidated.


